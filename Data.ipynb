{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "557a1c37-bca7-4e67-91e6-a8b49be059ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4\n",
    "import csv\n",
    "import os\n",
    "import hashlib\n",
    "import logging\n",
    "from subprocess import run as srun\n",
    "from urllib.parse import urlparse\n",
    "from itertools import product\n",
    "import time\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f454f32-3d44-4a50-b10e-68adf554ceb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88d225ba-2f74-472f-8842-13ff003c2987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def download(uri, ofile, md5):\n",
    "#     srun(['curl', '-s', '-o', ofile, uri], capture_output=True, check=True)\n",
    "#     md5dld = str(hashlib.md5(open(ofile, 'rb').read()).hexdigest())\n",
    "#     if md5 != md5dld:\n",
    "#         logging.warning(\"%s != %s\", md5, md5dld)\n",
    "#         logging.info(\"uri %s (%s == %s) : %s\", uri, md5, md5dld, ofile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "123a5417-b4c9-4062-a787-d2a39a96841f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# years=[1985]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "452cc647-e414-46fa-80c2-a1aede9e2a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models=['EC-Earth3_','TaiESM1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27caa0e7-b25c-4517-8569-4a37b4524dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scenarios=['historical','ssp126','ssp370']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8e46ac2-1cd4-4261-b653-6175186731eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables=['pr','sfcWind']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95921142-eadb-4394-b511-7f1820fd76de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# future_1=list(range(2025, 2046))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "210a92da-2872-4bc9-a74e-a7d7906ab3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# future_2=list(range(2045, 2066))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f67e7922-93e2-467f-9413-607da258b12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('gddp-cmip6-thredds-fileserver.csv') as index:\n",
    "#     fobjects = csv.reader(index)\n",
    "#     next(fobjects)\n",
    "#     for objs in fobjects:\n",
    "#         md5, uri = [o.strip() for o in objs]\n",
    "#         prsout = urlparse(uri)\n",
    "#         ofile = os.path.split(prsout.path)[1]\n",
    "\n",
    "#         if (any(str(year) in ofile for year in years) and\n",
    "#             any(model in ofile for model in models) and\n",
    "#             any(variable in ofile for variable in variables) and\n",
    "#             any(scenario in ofile for scenario in scenarios)):\n",
    "\n",
    "#             print(f\"Downloading: {ofile}\")  # Debug print\n",
    "#             download(uri, ofile, md5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abbcf48-04ff-4cc8-ac17-30d3498ccdbc",
   "metadata": {},
   "source": [
    "**DOWNLOAD RASTER ONLY FOR URUGUAY REGION**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6ee990-f68c-4da3-a83b-21505e95bfc3",
   "metadata": {},
   "source": [
    "I developed this function to download a dataset, clip it to the geometry of Uruguay, and then remove the original dataset, keeping only the portion that covers Uruguay. The code was adapted from NASA's official website (https://www.nccs.nasa.gov/services/data-collections/land-based-products/nex-gddp-cmip6) and from this repository (https://github.com/RaphaelPB/CRVA_tool/blob/main/1-DownloadAndFormatData/Download_NEX-GDDP-CMIP6.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e446433-c91f-48ed-83b9-fc6c968c270b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_and_download(csv_path, years, models, variables, scenarios, shape):\n",
    "    \"\"\"\n",
    "    Downloads, filters, and processes climate data files based on specific criteria (years, models, variables, scenarios).\n",
    "    The data is clipped to the Uruguay region, and variables such as precipitation are converted if necessary.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    csv_path : str\n",
    "        Path to the CSV file containing the index of datasets to download.\n",
    "    years : list of int\n",
    "        List of years to filter the datasets.\n",
    "    models : list of str\n",
    "        List of model names to filter the datasets.\n",
    "    variables : list of str\n",
    "        List of variables (e.g., 'pr', 'tas') to filter the datasets.\n",
    "    scenarios : list of str\n",
    "        List of climate scenarios (e.g., 'rcp45', 'rcp85') to filter the datasets.\n",
    "    shape : geopandas.GeoDataFrame\n",
    "        A GeoDataFrame containing the geometry (e.g., of Uruguay) to clip the data.\n",
    "    \n",
    "    This function downloads files matching the specified criteria, processes them (including clipping to a region),\n",
    "    and stores the results in NetCDF format, while cleaning up by deleting the original unfiltered files.\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(csv_path) as index:\n",
    "        fobjects = csv.reader(index) # Read the CSV file containing dataset metadata\n",
    "        next(fobjects)  # Skip header\n",
    "\n",
    "        # Loop through each file entry in the CSV and apply the filtering criteria\n",
    "        for objs in fobjects:\n",
    "            md5, uri = [o.strip() for o in objs]\n",
    "\n",
    "            # Extract the filename from the URL to check against the filtering criteria\n",
    "            prsout = urlparse(uri)\n",
    "            ofile = os.path.split(prsout.path)[1]\n",
    "    \n",
    "            # Download the file only if it matches the filtering criteria\n",
    "            if any(str(year) in ofile for year in years) and \\\n",
    "               any(model in ofile for model in models) and \\\n",
    "               any(variable in ofile for variable in variables) and \\\n",
    "               any(scenario in ofile for scenario in scenarios):\n",
    "        \n",
    "                print(f\"Downloading: {ofile}\")  # Print the filename being downloaded for debugging purposes\n",
    "        \n",
    "                # Download the file using the provided URI \n",
    "                download(uri, ofile, md5)\n",
    "\n",
    "                filename = os.path.splitext(os.path.basename(uri))[0]\n",
    "        \n",
    "                # Open the downloaded dataset using xarray\n",
    "                data = os.path.join(os.getcwd(), ofile)  # Update with correct path\n",
    "                ds_GDDP6 = xr.open_dataset(data)\n",
    "        \n",
    "                # Set spatial dims and CRS\n",
    "                ds_GDDP6 = ds_GDDP6.rio.set_spatial_dims(x_dim=\"lon\", y_dim=\"lat\")\n",
    "                ds_GDDP6.rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "                ds_GDDP6.coords['lon'] = (ds_GDDP6.coords['lon'] + 180) % 360 - 180\n",
    "                ds_GDDP6 = ds_GDDP6.sortby(ds_GDDP6.lon)\n",
    "        \n",
    "                # Clip the data to the Uruguay region\n",
    "                ds_GDDP6 = ds_GDDP6.rio.set_spatial_dims(x_dim=\"lon\", y_dim=\"lat\")\n",
    "                ds_masked = ds_GDDP6.rio.clip(shape.geometry, shape.crs, drop=True)\n",
    "\n",
    "                if 'pr' in variables:\n",
    "                    secs_in_a_day = 24 * 60 * 60\n",
    "                    ds_masked['pr_mmd'] = (ds_masked['pr'] * secs_in_a_day).round(2).astype('float32') # Convert to mm/day\n",
    "        \n",
    "                # Save the filtered data to a NetCDF file\n",
    "                ds_masked.to_netcdf(f\"filtered_data/{filename}_masked.nc\")\n",
    "        \n",
    "                # Delete the original unfiltered file to save space\n",
    "                os.remove(data)\n",
    "                print(f\"Deleted original unfiltered file: {ofile}\")\n",
    "        \n",
    "                # Explicitly close datasets to free memory\n",
    "                ds_GDDP6.close()\n",
    "                ds_masked.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "169e13ad-3fd3-4f1f-bc32-33a00b7c497c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/pyogrio/geopandas.py:265: UserWarning: More than one layer found in 'ury_adm_2020_shp.zip': 'ury_admbnda_adm0_2020' (default), 'ury_admbnda_adm1_2020', 'ury_admbnda_adm2_2020', 'ury_admbndl_ALL_2020'. Specify layer parameter to avoid this warning.\n",
      "  result = read_func(\n"
     ]
    }
   ],
   "source": [
    "# Define the shapefile for Uruguay area (using GeoPandas)\n",
    "shape = gpd.read_file(\"ury_adm_2020_shp.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ae367ea-e6e6-493f-9794-60b6dc9b33b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the filtering parameters\n",
    "years = list(range(2038, 2039)) #list(range(2055, 2065)) # #list(range(1985, 2015))\n",
    "models= ['TaiESM1'] #['TaiESM1'] #['EC-Earth3_'] \n",
    "variables = ['pr'] #['sfcWind'] #[\"pr\"] #['tas_']\n",
    "scenarios = ['ssp126'] #[\"historical\"] #['ssp126'] #['ssp370'] # #[\"historical\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc33d931-94ca-4f84-895f-41fdc105fd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: pr_day_TaiESM1_ssp126_r1i1p1f1_gn_2038.nc\n",
      "Deleted original unfiltered file: pr_day_TaiESM1_ssp126_r1i1p1f1_gn_2038.nc\n"
     ]
    }
   ],
   "source": [
    "# Run the process\n",
    "filter_and_download('gddp-cmip6-thredds-fileserver.csv', years, models, variables, scenarios, shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
